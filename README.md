<p align="center">
<img width="300" src="assets/logo.png">
</p>

<p align="center">
<a href="https://trendshift.io/repositories/15323" target="_blank"><img src="https://trendshift.io/api/badge/repositories/15323" alt="GeeeekExplorer%2Fnano-vllm | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>
</p>

# Nano-vLLM

A lightweight vLLM implementation built from scratch.

## Key Features

* ğŸš€ **Fast offline inference** - Comparable inference speeds to vLLM
* ğŸ“– **Readable codebase** - Clean implementation in ~ 1,200 lines of Python code
* âš¡ **Optimization Suite** - Prefix caching, Tensor Parallelism, Torch compilation, CUDA graph, etc.
* ğŸ§  **SnapKV Sparse Cache** - Optional attention-score-based KV selection with post-prefill truncation to shrink decode working set

## Installation

```bash
pip install git+https://github.com/GeeeekExplorer/nano-vllm.git
```

## Model Download

To download the model weights manually, use the following command:
```bash
huggingface-cli download --resume-download Qwen/Qwen3-0.6B \
  --local-dir ~/huggingface/Qwen3-0.6B/ \
  --local-dir-use-symlinks False
```

## Quick Start

See `example.py` for usage. The API mirrors vLLM's interface with minor differences in the `LLM.generate` method:
```python
from nanovllm import LLM, SamplingParams
llm = LLM("/YOUR/MODEL/PATH", enforce_eager=True, tensor_parallel_size=1)
sampling_params = SamplingParams(temperature=0.6, max_tokens=256)
prompts = ["Hello, Nano-vLLM."]
outputs = llm.generate(prompts, sampling_params)
outputs[0]["text"]
```

## Benchmark

See `bench.py` for benchmark.

## SnapKV (Sparse KV Cache)

- ä½œç”¨ï¼šprefill é˜¶æ®µå…ˆå…¨é‡å†™ KVï¼ŒéšåæŒ‰æ³¨æ„åŠ›å¾—åˆ†ä¿ç•™æœ€é‡è¦çš„ `snapkv_limit` ä¸ª tokenï¼Œå…¶ä½™å¯¹åº” KV å—åœ¨è°ƒåº¦å™¨ä¾§å›æ”¶ï¼Œæ˜¾è‘—é™ä½é•¿ä¸Šä¸‹æ–‡ä¸‹çš„ decode ä»£ä»·ã€‚
- é€‰æ‹©ç®—æ³•ï¼šå¯¹æ¯ä¸ªåºåˆ—å–æœ«å°¾ `snapkv_attn_sample_queries`ï¼ˆé»˜è®¤ 128ï¼‰ä¸ª queryï¼Œä¸å…¨é‡ key åšå› æœæ³¨æ„åŠ›ï¼Œæ±‡æ€»å¤´ä¸é‡‡æ · query çš„æƒé‡ï¼ŒæŒ‰åˆ†æ•° Top-Kï¼ˆK=`snapkv_limit`ï¼‰é€‰å–ä¿ç•™ã€‚
- å…³é”®å‚æ•°ï¼š
  - `enable_snapkv`: å¼€å¯/å…³é—­ SnapKVã€‚
  - `snapkv_limit`: æ¯åºåˆ—ä¿ç•™çš„æœ€å¤§ token æ•°ï¼ˆé»˜è®¤ç­‰äº `max_model_len`ï¼Œå¯è°ƒå°ä»¥å¼ºåˆ¶ç¨€ç–åŒ–ï¼‰ã€‚
  - `snapkv_attn_sample_queries`: å‚ä¸æ‰“åˆ†çš„æœ«å°¾ query æ•°ï¼Œç”¨äºæ§åˆ¶æ˜¾å­˜/ç®—é‡ã€‚
- å¿«é€Ÿè¯•ç”¨ï¼š
```python
from nanovllm import LLM, SamplingParams
llm = LLM(
    "/YOUR/MODEL/PATH",
    enable_snapkv=True,
    snapkv_limit=2048,               # ä¿ç•™ token ä¸Šé™
    snapkv_attn_sample_queries=128,  # æ‰“åˆ†ä½¿ç”¨çš„æœ«å°¾æŸ¥è¯¢æ•°
    enforce_eager=True,
)
prompts = ["Hello SnapKV!"]
sampling_params = SamplingParams(temperature=0.6, max_tokens=128)
print(llm.generate(prompts, sampling_params)[0]["text"])
```

**Test Configuration:**
- Hardware: RTX 4070 Laptop (8GB)
- Model: Qwen3-0.6B
- Total Requests: 256 sequences
- Input Length: Randomly sampled between 100â€“1024 tokens
- Output Length: Randomly sampled between 100â€“1024 tokens

**Performance Results:**
| Inference Engine | Output Tokens | Time (s) | Throughput (tokens/s) |
|----------------|-------------|----------|-----------------------|
| vLLM           | 133,966     | 98.37    | 1361.84               |
| Nano-vLLM      | 133,966     | 93.41    | 1434.13               |


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=GeeeekExplorer/nano-vllm&type=Date)](https://www.star-history.com/#GeeeekExplorer/nano-vllm&Date)